{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config of inputs\n",
    "out_dir = 'data'\n",
    "out_version = 'v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection = pickle.load(open( \"{}/Xy_collection_{}.pickle\".format(out_dir, out_version), \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_train_raw_StandardScaler', 'X_test_pca_mini_MinMaxScaler', 'X_train_pca_mini', 'X_test_pca_full_MinMaxScaler', 'X_test_pca_mini_StandardScaler', 'X_train_pca_trunk_StandardScaler', 'X_test_pca_mini', 'X_valid_pca_trunk_StandardScaler', 'X_valid_raw', 'X_valid_pca_full_MinMaxScaler', 'X_valid_ica_mini_StandardScaler', 'X_test_pca_full', 'X_valid_ica_full_MinMaxScaler', 'X_train_ica_full', 'X_test_raw_StandardScaler', 'X_test_raw', 'X_test_ica_full_StandardScaler', 'y_train', 'X_train_pca_trunk_MinMaxScaler', 'X_train_raw', 'X_valid_pca_mini_MinMaxScaler', 'X_train_raw_MinMaxScaler', 'X_valid_pca_trunk_MinMaxScaler', 'X_test_pca_trunk', 'X_test_pca_trunk_StandardScaler', 'X_valid_pca_trunk', 'X_train_ica_mini_MinMaxScaler', 'X_train_pca_full_StandardScaler', 'X_valid_ica_full', 'X_train_ica_mini', 'X_test_ica_full', 'X_train_pca_trunk', 'X_train_pca_mini_StandardScaler', 'X_train_pca_full', 'X_train_pca_full_MinMaxScaler', 'X_valid_pca_full', 'X_test_pca_full_StandardScaler', 'X_test_ica_mini_MinMaxScaler', 'X_test_ica_mini_StandardScaler', 'X_valid_ica_mini_MinMaxScaler', 'X_train_ica_full_StandardScaler', 'X_valid_pca_mini_StandardScaler', 'X_valid_raw_StandardScaler', 'X_train_pca_mini_MinMaxScaler', 'X_test_ica_full_MinMaxScaler', 'X_valid_raw_MinMaxScaler', 'X_valid_ica_full_StandardScaler', 'X_valid_pca_full_StandardScaler', 'X_valid_ica_mini', 'X_train_ica_mini_StandardScaler', 'X_valid_pca_mini', 'X_train_ica_full_MinMaxScaler', 'X_test_raw_MinMaxScaler', 'y_valid', 'X_test_ica_mini', 'X_test_pca_trunk_MinMaxScaler'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [s[len('X_train_'):] for s in  df_collection.keys() if 'X_train' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_StandardScaler',\n",
       " 'pca_mini',\n",
       " 'pca_trunk_StandardScaler',\n",
       " 'ica_full',\n",
       " 'pca_trunk_MinMaxScaler',\n",
       " 'raw',\n",
       " 'raw_MinMaxScaler',\n",
       " 'ica_mini_MinMaxScaler',\n",
       " 'pca_full_StandardScaler',\n",
       " 'ica_mini',\n",
       " 'pca_trunk',\n",
       " 'pca_mini_StandardScaler',\n",
       " 'pca_full',\n",
       " 'pca_full_MinMaxScaler',\n",
       " 'ica_full_StandardScaler',\n",
       " 'pca_mini_MinMaxScaler',\n",
       " 'ica_mini_StandardScaler',\n",
       " 'ica_full_MinMaxScaler']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added to suppress warnings from model fiting of type\n",
    "# DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'The truth value of an empty array is ambiguous. .*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "from sklearn.metrics import make_scorer,roc_auc_score\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================  500  =================\n",
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "{'subsample': 0.7874833473239866, 'max_depth': 10, 'reg_lambda': 5, 'min_child_weight': 2, 'colsample_bytree': 0.9980714989053638, 'reg_alpha': 0.1}\n",
      "0.843644544431946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "cv_results=[]\n",
    "xgb_param_test_list = [{'max_depth': [2,3,4,5,6,8,10],\n",
    "                    'min_child_weight': sp_randint(1, 10),\n",
    "                    'subsample': sp_uniform(loc=0.6, scale=0.4), \n",
    "                    'colsample_bytree': sp_uniform(loc=0.85, scale=0.15),\n",
    "                    'reg_alpha': [0, 1e-5, 1e-3, 1e-1, 1, 3, 5, 10],\n",
    "                    'reg_lambda': [0, 1e-5, 1e-3, 1e-1, 1, 5, 10]}]\n",
    "\n",
    "n_iter = [500]\n",
    "clf=xgb.XGBClassifier(max_depth=-1, random_state=314, seed=314, silent=True, metric='None', n_jobs=2)\n",
    "\n",
    "for n, param_test in zip(n_iter, xgb_param_test_list):\n",
    "    print('============================ ', n, ' =================')\n",
    "    gs1 = RandomizedSearchCV(estimator=clf, param_distributions=param_test, \n",
    "                             n_iter=n,\n",
    "                             scoring=make_scorer(accuracy_score, greater_is_better=True),\n",
    "                             cv=4,\n",
    "                             random_state=314,\n",
    "                             verbose=True)\n",
    "    #gs1.fit(df_collection['X_train_{}'.format('raw')] , df_collection['y_train'])\n",
    "    gs1.fit(pd.concat([df_collection['X_train_{}'.format('raw')],\n",
    "                       df_collection['X_valid_{}'.format('raw')]]), \n",
    "            pd.concat([df_collection['y_train'],\n",
    "                       df_collection['y_valid']]))\n",
    "    print(gs1.best_params_)\n",
    "    print(gs1.best_score_)\n",
    "    cv_results.append(gs1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8391451068616423 0.8743905074489782   :  {'subsample': 0.8096846675195573, 'max_depth': 5, 'reg_lambda': 0, 'min_child_weight': 8, 'colsample_bytree': 0.9333099791181296, 'reg_alpha': 0.1}\n",
      "0.8391451068616423 0.8871403262332798   :  {'subsample': 0.7557660954844897, 'max_depth': 5, 'reg_lambda': 1e-05, 'min_child_weight': 4, 'colsample_bytree': 0.8706589383900514, 'reg_alpha': 1}\n",
      "0.8402699662542182 0.8758914461688074   :  {'subsample': 0.8837227061346042, 'max_depth': 10, 'reg_lambda': 0.1, 'min_child_weight': 8, 'colsample_bytree': 0.9336018589755691, 'reg_alpha': 0}\n",
      "0.8413948256467941 0.8833910747329039   :  {'subsample': 0.7905535081311607, 'max_depth': 8, 'reg_lambda': 1e-05, 'min_child_weight': 6, 'colsample_bytree': 0.9356188122231713, 'reg_alpha': 1}\n",
      "0.843644544431946 0.9066373344859101   :  {'subsample': 0.7874833473239866, 'max_depth': 10, 'reg_lambda': 5, 'min_child_weight': 2, 'colsample_bytree': 0.9980714989053638, 'reg_alpha': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlisovyi/anaconda2/envs/Titanic/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(cv_results[0]['mean_test_score'])[-5:]:\n",
    "    print('{1} {2}   :  {0}'.format(cv_results[0]['params'][i], \n",
    "                                    cv_results[0]['mean_test_score'][i], \n",
    "                                    cv_results[0]['mean_train_score'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_validate(xgb.XGBClassifier(max_depth=3, random_state=314, silent=True, metric='None', n_jobs=2),\n",
    "                       X=df_collection['X_train_{}'.format('raw')],\n",
    "                       y=df_collection['y_train'],\n",
    "                       scoring=make_scorer(accuracy_score, greater_is_better=True),\n",
    "                       cv=4,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03130794, 0.03370237, 0.02735114, 0.02837324]),\n",
       " 'score_time': array([0.00253081, 0.00179887, 0.00180984, 0.00253487]),\n",
       " 'test_score': array([0.80769231, 0.80128205, 0.82580645, 0.81818182]),\n",
       " 'train_score': array([0.89247312, 0.89677419, 0.89270386, 0.90364026])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================  500  =================\n",
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "{'subsample': 0.9719454235733966, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 3, 'colsample_bytree': 0.874435683963595, 'num_leaves': 7}\n",
      "0.843644544431946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "lgb_cv_results = [] \n",
    "lgb_param_test_list = [{'num_leaves': sp_randint(6, 10),\n",
    "                    'min_child_weight': sp_randint(1, 50),\n",
    "                    'colsample_bytree': sp_uniform(loc=0.7, scale=0.3), \n",
    "                    'subsample': sp_uniform(loc=0.7, scale=0.3),\n",
    "                    'reg_alpha': [0, 1e-5, 1e-3, 1e-1, 1, 2],\n",
    "                    'reg_lambda': [0, 1e-5, 1e-3, 1e-1, 1, 2]}]\n",
    "\n",
    "n_iter = [500]\n",
    "clf=lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=2)\n",
    "\n",
    "for n, param_test in zip(n_iter, lgb_param_test_list):\n",
    "    print('============================ ', n, ' =================')\n",
    "    gs2 = RandomizedSearchCV(estimator=clf, param_distributions=param_test, \n",
    "                             n_iter=n,\n",
    "                             scoring=make_scorer(accuracy_score, greater_is_better=True),\n",
    "                             cv=4,\n",
    "                             random_state=314,\n",
    "                             verbose=True)\n",
    "    #gs2.fit(df_collection['X_train_{}'.format('raw')] , df_collection['y_train'])\n",
    "    gs2.fit(pd.concat([df_collection['X_train_{}'.format('raw')],\n",
    "                       df_collection['X_valid_{}'.format('raw')]]), \n",
    "            pd.concat([df_collection['y_train'],\n",
    "                       df_collection['y_valid']]))\n",
    "    print(gs2.best_params_)\n",
    "    print(gs2.best_score_)\n",
    "    lgb_cv_results.append(gs2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402699662542182 0.8875145760453107   :  {'subsample': 0.7286759755581009, 'reg_alpha': 0.001, 'reg_lambda': 2, 'min_child_weight': 4, 'colsample_bytree': 0.825499562969686, 'num_leaves': 9}\n",
      "0.8402699662542182 0.8867666392029211   :  {'subsample': 0.7635777990829171, 'reg_alpha': 0.001, 'reg_lambda': 0, 'min_child_weight': 4, 'colsample_bytree': 0.7651577542988559, 'num_leaves': 7}\n",
      "0.8402699662542182 0.8882653267960615   :  {'subsample': 0.8370598352879277, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 2, 'colsample_bytree': 0.766300383073703, 'num_leaves': 8}\n",
      "0.8413948256467941 0.8995108301705004   :  {'subsample': 0.8291372597673844, 'reg_alpha': 0, 'reg_lambda': 0.001, 'min_child_weight': 4, 'colsample_bytree': 0.9117493957358069, 'num_leaves': 9}\n",
      "0.843644544431946 0.8878893886390138   :  {'subsample': 0.9719454235733966, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 3, 'colsample_bytree': 0.874435683963595, 'num_leaves': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlisovyi/anaconda2/envs/Titanic/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(lgb_cv_results[0]['mean_test_score'])[-5:]:\n",
    "    print('{1} {2}   :  {0}'.format(lgb_cv_results[0]['params'][i], \n",
    "                                    lgb_cv_results[0]['mean_test_score'][i], \n",
    "                                    lgb_cv_results[0]['mean_train_score'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
